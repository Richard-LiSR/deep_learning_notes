{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor创建方法"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 直接创建Tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## torch.tensor()\r\n",
    "## torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\r\n",
    "        # data: 数据，可以是 list，numpy\r\n",
    "        # dtype: 数据类型，默认与 data 的一致\r\n",
    "        # device: 所在设备，cuda/cpu\r\n",
    "        # requires_grad: 是否需要梯度\r\n",
    "        # pin_memory: 是否存于锁页内存\r\n",
    "# 其中数据类型既可以是numpy格式，也可以是list格式"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# numpy格式\r\n",
    "arr = np.ones((3, 3))\r\n",
    "# 创建存放在 GPU 的数据\r\n",
    "# t = torch.tensor(arr, device='cuda')\r\n",
    "t= torch.tensor(arr)\r\n",
    "print(t)\r\n",
    "# 列表格式\r\n",
    "x = torch.tensor([1,2,3,4])\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# torch.from_numpy(ndarray) → Tensor\r\n",
    "a = np.arange(12).reshape(3,4) #numpy只能通过reshape来实现多维数组\r\n",
    "y = torch.from_numpy(a)\r\n",
    "# 利用这个方法创建的 tensor 和原来的 ndarray 共享内存，当修改其中一个数据，另外一个也会被改动。[可以直接通过切片来修改数据]\r\n",
    "y[2,0] = 9\r\n",
    "print(y)\r\n",
    "print(a)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 9,  9, 10, 11]])\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 9  9 10 11]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 根据数值创建Tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.zeros()\r\n",
    "# torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\r\n",
    "        # size: 张量的形状\r\n",
    "        # out: 输出的张量，如果指定了 out，那么torch.zeros()返回的张量和 out 指向的是同一个地址\r\n",
    "        # layout: 内存中布局形式，有 strided，sparse_coo 等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。\r\n",
    "        # device: 所在设备，cuda/cpu\r\n",
    "        # requires_grad: 是否需要梯度\r\n",
    "\"\"\" \r\n",
    "同理还有 torch.ones()，torch.ones_like() \r\n",
    "\"\"\"\r\n",
    "# torch.zeros_like\r\n",
    "# torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)\r\n",
    "        # 功能：根据 input 形状创建全 0 张量\r\n",
    "        # input: 创建与 input 同形状的全 0 张量\r\n",
    "        # dtype: 数据类型\r\n",
    "        # layout: 内存中布局形式，有 strided，sparse_coo 等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "out_t = torch.tensor([1,4,5])\r\n",
    "t = torch.zeros((3, 3), out=out_t) #此时的out_t已经被覆盖成t\r\n",
    "# 指定out应该是将新建的zero张量写入到out张量中，不指定out则新建一个张量。然后无论如何，返回表示这个新的全0矩阵的张量\r\n",
    "print(t, '\\n', out_t)\r\n",
    "# id 是取内存地址。最终 t 和 out_t 是同一个内存地址\r\n",
    "print(id(t), id(out_t), id(t) == id(out_t))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]) \n",
      " tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "140561611294720 140561611294720 True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.full()\r\n",
    "# torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\r\n",
    "        # 功能：创建自定义数值的张量\r\n",
    "        # size: 张量的形状，如(3, 3)\r\n",
    "        # fill_value: 张量中每一个元素的值\r\n",
    "# torch.full_like()和torch.zeros_like相同"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t = torch.full((3, 3), 1)\r\n",
    "print(t)\r\n",
    "# 这种只能创建数据相同的张量"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.arange()\r\n",
    "# torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\r\n",
    "# 创建等差的一维张量\r\n",
    "        # 功能：创建等差的 1 维张量。注意区间为[start, end)。\r\n",
    "        # start: 数列起始值\r\n",
    "        # end: 数列结束值，开区间，取不到结束值\r\n",
    "        # step: 数列公差，默认为 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "t = torch.arange(2, 10, 2)\r\n",
    "print(t)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 4, 6, 8])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.linspace()\r\n",
    "# torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\r\n",
    "        # 功能：创建均分的 1 维张量。数值区间为[start, end]\r\n",
    "        # start: 数列起始值\r\n",
    "        # end: 数列结束值\r\n",
    "        # steps: 数列长度(元素个数)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "t = torch.linspace(2, 10, 6)\r\n",
    "print(t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 2.0000,  3.6000,  5.2000,  6.8000,  8.4000, 10.0000])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 根据概率创建 Tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# torch.normal()\r\n",
    "# torch.normal(mean, std, *, generator=None, out=None)\r\n",
    "        # 功能：生成正态分布(高斯分布) \r\n",
    "                # 数据可能是围绕着一个中心分布，不偏左、不偏右、也不或高或低，呈现一种中间高、两边低的趋势，我们称之为“正态分布”：\r\n",
    "        # mean: 均值\r\n",
    "        # std: 标准差\r\n",
    "# 共有四种方式"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1、mean 为标量，std 为标量。这时需要设置 size。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# mean：标量 std: 标量\r\n",
    "# 这里需要设置 size   size: _size, *\r\n",
    "t_normal = torch.normal(0, 1, size=(4,))\r\n",
    "print(t_normal)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.4286,  1.4078, -0.8289,  0.3476])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2、mean 为标量，std 为张量"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# mean：标量 std: 张量\r\n",
    "mean = 2\r\n",
    "std = torch.arange(1, 5, dtype=torch.float)\r\n",
    "t_normal = torch.normal(mean, std)\r\n",
    "print(\"mean:{}\\nstd:{}\".format(mean, std))\r\n",
    "print(t_normal)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean:2\n",
      "std:tensor([1., 2., 3., 4.])\n",
      "tensor([ 3.2278,  3.2841,  3.7933, -0.5807])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3、mean 为张量，std 为标量"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# mean：张量 std: 标量\r\n",
    "mean = torch.arange(1, 5, dtype=torch.float)\r\n",
    "std = 1\r\n",
    "t_normal = torch.normal(mean, std)\r\n",
    "print(\"mean:{}\\nstd:{}\".format(mean, std))\r\n",
    "print(t_normal)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean:tensor([1., 2., 3., 4.])\n",
      "std:1\n",
      "tensor([-1.2212,  2.4317,  3.1891,  3.4174])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4、mean 为张量，std 为张量"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# mean：张量 std: 张量\n",
    "mean = torch.arange(1, 5, dtype=torch.float)\n",
    "std = torch.arange(1, 5, dtype=torch.float)\n",
    "t_normal = torch.normal(mean, std)\n",
    "print(\"mean:{}\\nstd:{}\".format(mean, std))\n",
    "print(t_normal)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean:tensor([1., 2., 3., 4.])\n",
      "std:tensor([1., 2., 3., 4.])\n",
      "tensor([0.3530, 0.3780, 4.7195, 4.9932])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.randn() 和 torch.randn_like()\n",
    "# torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "        # 功能：生成标准正态分布。\n",
    "        # size: 张量的形状\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "x = torch.randn(3,4)\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.2673,  1.7223,  0.0696,  0.1807],\n",
       "        [ 1.7121, -0.0554, -0.0431,  0.8940],\n",
       "        [-1.5080, -0.9476,  0.0425,  0.1670]])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.rand() 和 torch.rand_like()\n",
    "# torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "        # 功能：在区间 [0, 1) 上生成均匀分布。"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "x = torch.rand(3, 4)\n",
    "x\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4748, 0.4836, 0.7356, 0.9461],\n",
       "        [0.1866, 0.1128, 0.6700, 0.1265],\n",
       "        [0.9056, 0.1615, 0.9719, 0.8020]])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# torch.randint() 和 torch.randint_like()\n",
    "# randint(low=0, high, size, *, generator=None, out=None,dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "        # 功能：在区间[low, high) 上生成整数均匀分布。\n",
    "        # size: 张量的形状"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "x = torch.randint(0,5,size=(4,))\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 4, 4, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}