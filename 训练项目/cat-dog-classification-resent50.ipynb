{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-09-02T06:53:12.1223Z","iopub.status.busy":"2021-09-02T06:53:12.121987Z","iopub.status.idle":"2021-09-02T06:53:12.58313Z","shell.execute_reply":"2021-09-02T06:53:12.5822Z","shell.execute_reply.started":"2021-09-02T06:53:12.122266Z"}},"source":["# 定义模型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-09-02T07:07:25.86069Z","iopub.status.busy":"2021-09-02T07:07:25.860337Z","iopub.status.idle":"2021-09-02T07:25:31.877778Z","shell.execute_reply":"2021-09-02T07:25:31.876943Z","shell.execute_reply.started":"2021-09-02T07:07:25.860661Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import torchvision.models.resnet\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n","                               kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channel)\n","        self.relu = nn.ReLU()\n","        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n","                               kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channel)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    \"\"\"\n","    注意：原论文中，在虚线残差结构的主分支上，第一个1x1卷积层的步距是2，第二个3x3卷积层步距是1。\n","    但在pytorch官方实现过程中是第一个1x1卷积层的步距是1，第二个3x3卷积层步距是2，\n","    这么做的好处是能够在top1上提升大概0.5%的准确率。\n","    可参考Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch\n","    \"\"\"\n","    expansion = 4\n","\n","    def __init__(self, in_channel, out_channel, stride=1, downsample=None,\n","                 groups=1, width_per_group=64):\n","        super(Bottleneck, self).__init__()\n","\n","        width = int(out_channel * (width_per_group / 64.)) * groups\n","\n","        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,\n","                               kernel_size=1, stride=1, bias=False)  # squeeze channels\n","        self.bn1 = nn.BatchNorm2d(width)\n","        # -----------------------------------------\n","        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,\n","                               kernel_size=3, stride=stride, bias=False, padding=1)\n","        self.bn2 = nn.BatchNorm2d(width)\n","        # -----------------------------------------\n","        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel * self.expansion,\n","                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels\n","        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self,\n","                 block,\n","                 blocks_num,\n","                 num_classes=1000,\n","                 include_top=True,\n","                 groups=1,\n","                 width_per_group=64):\n","        super(ResNet, self).__init__()\n","        self.include_top = include_top\n","        self.in_channel = 64\n","\n","        self.groups = groups\n","        self.width_per_group = width_per_group\n","\n","        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n","                               padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(self.in_channel)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n","        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n","        if self.include_top:\n","            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)\n","            self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(\n","                    m.weight, mode='fan_out', nonlinearity='relu')\n","\n","    def _make_layer(self, block, channel, block_num, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_channel != channel * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.in_channel, channel * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(channel * block.expansion))\n","\n","        layers = []\n","        layers.append(block(self.in_channel,\n","                            channel,\n","                            downsample=downsample,\n","                            stride=stride,\n","                            groups=self.groups,\n","                            width_per_group=self.width_per_group))\n","        self.in_channel = channel * block.expansion\n","\n","        for _ in range(1, block_num):\n","            layers.append(block(self.in_channel,\n","                                channel,\n","                                groups=self.groups,\n","                                width_per_group=self.width_per_group))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        if self.include_top:\n","            x = self.avgpool(x)\n","            x = torch.flatten(x, 1)\n","            x = self.fc(x)\n","\n","        return x\n","\n","\n","def resnet34(num_classes=1000, include_top=True):\n","    # https://download.pytorch.org/models/resnet34-333f7ec4.pth\n","    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n","\n","\n","def resnet50(num_classes=1000, include_top=True):\n","    # https://download.pytorch.org/models/resnet50-19c8e357.pth\n","    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n","\n","\n","def resnet101(num_classes=1000, include_top=True):\n","    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n","    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)\n","\n","\n","def resnext50_32x4d(num_classes=1000, include_top=True):\n","    # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\n","    groups = 32\n","    width_per_group = 4\n","    return ResNet(Bottleneck, [3, 4, 6, 3],\n","                  num_classes=num_classes,\n","                  include_top=include_top,\n","                  groups=groups,\n","                  width_per_group=width_per_group)\n","\n","\n","def resnext101_32x8d(num_classes=1000, include_top=True):\n","    # https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\n","    groups = 32\n","    width_per_group = 8\n","    return ResNet(Bottleneck, [3, 4, 23, 3],\n","                  num_classes=num_classes,\n","                  include_top=include_top,\n","                  groups=groups,\n","                  width_per_group=width_per_group)\n","\n","\n","resnet = resnet50()\n","print(resnet)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","import os.path\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from tqdm import tqdm\n","import torchvision.models.resnet\n","\n","\n","def main():\n","    # 训练\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"using {}\".format(device))\n","    # 对花朵数据集进行预处理\n","    data_transform = {\n","        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n","                                     transforms.RandomHorizontalFlip(),\n","                                     transforms.ToTensor(),\n","                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n","        \"val\": transforms.Compose([transforms.Resize(256),\n","                                   transforms.CenterCrop(224),\n","                                   transforms.ToTensor(),\n","                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","    }\n","\n","    #    准备数据集\n","    # ./ 表示当前目录\n","    # ../ 表示父级目录\n","    # ../.. 表示祖父目录\n","\n","#     data_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))  # 父级工作目录\n","    image_path = \"../input/flower-date/flower_data\"  # 将目录拼接起来\n","    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n","    # 制造训练集和验证集\n","    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"), transform=data_transform[\"train\"])\n","    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n","                                            transform=data_transform[\"val\"])\n","    val_num = len(validate_dataset)\n","    train_num = len(train_dataset)  # 训练集数量大小\n","\n","    flower_list = train_dataset.class_to_idx  # 返回其类别索引\n","    cla_dict = dict(\n","        (val, key) for key, val in flower_list.items())  # items() 方法把字典中每对 key 和 value 组成一个元组，并把这些元组放在列表中返回。\n","\n","    batch_size = 300\n","    train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=0)\n","    validate_loader = DataLoader(validate_dataset, batch_size=300, shuffle=True, num_workers=0)\n","    # dataloader本质是一个可迭代对象，使用iter()访问，不能使用next()访问；\n","    # 使用iter(dataloader)返回的是一个迭代器，然后可以使用next访问\n","    print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n","\n","    # 实例化模型\n","    # 预训练\n","    net = resnet34()\n","    # 加载预训练权重\n","    # load pretrain weights\n","    model_weight_path = \"../input/weights/resnet34.pth\"\n","    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n","    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n","\n","    # change fc layer structure\n","    in_channel = net.fc.in_features\n","    net.fc = nn.Linear(in_channel, 5)\n","    net.to(device)\n","\n","    # define loss function\n","    loss_func = nn.CrossEntropyLoss()\n","\n","    # construct an optimizer\n","    params = [p for p in net.parameters() if p.requires_grad]\n","    optimizer = optim.Adam(params, lr=0.0001)\n","\n","    epochs = 5\n","    save_path = './weights/resNet34.pth'\n","\n","    best_acc = 0.0\n","    train_step = len(train_loader)\n","    for epoch in range(epochs):\n","        #     train\n","        net.train()\n","        running_loss = 0.0\n","        train_bar = tqdm(train_loader)\n","        for step, data in enumerate(train_bar):\n","            images, labels = data\n","            optimizer.zero_grad()\n","            outputs = net(images.to(device))\n","            loss = loss_func(outputs, labels.to(device))\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs,\n","                                                                     loss)\n","            # train_bar.desc = … 的操作是为了能够看到训练的实施进度\n","            # % f保留小数点后面六位有效数字， % .3f保留三位小数\n","\n","        net.eval()\n","        acc = 0.0\n","        with torch.no_grad():\n","            val_bar = tqdm(validate_loader)\n","            for val_data in val_bar:\n","                val_images, val_labels = val_data\n","                outputs = net(val_images.to(device))\n","                predicted_y = torch.max(outputs, dim=1)[1]\n","                acc += torch.eq(predicted_y, val_labels.to(device)).sum().item()\n","                # 利用输出outputs的预测的标签和真实标签进行比较，相等为1，不同为零,进行累加最后除以验证集样本数\n","\n","            val_accurate = acc / val_num\n","            print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' % (\n","                epoch + 1, running_loss / train_step, val_accurate))\n","            if val_accurate > best_acc:\n","                best_acc = val_accurate\n","                torch.save(net.state_dict(), save_path)\n","    print(\"Finished Training\")\n","\n","\n","if __name__ == '__main__':\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-09-02T07:39:10.745974Z","iopub.status.busy":"2021-09-02T07:39:10.745658Z","iopub.status.idle":"2021-09-02T07:39:11.495719Z","shell.execute_reply":"2021-09-02T07:39:11.494866Z","shell.execute_reply.started":"2021-09-02T07:39:10.745945Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","import torch\n","from PIL import Image\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","# from resnet import resnet34\n","\n","\n","def main():\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    data_transform = transforms.Compose(\n","        [transforms.Resize(256),\n","         transforms.CenterCrop(224),\n","         transforms.ToTensor(),\n","         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","\n","    # load image\n","    img_path = \"../input/catdog/dog.jpg\"\n","    assert os.path.exists(img_path), \"file: '{}' dose not exist.\".format(img_path)\n","    img = Image.open(img_path)\n","\n","    plt.imshow(img)\n","    # [N, C, H, W]\n","    img = data_transform(img)\n","    # expand batch dimension\n","    img = torch.unsqueeze(img, dim=0)\n","\n","    # read class_indict\n","    json_path = '../input/catdog-json/class_indices.json'\n","    assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n","\n","    json_file = open(json_path, \"r\")\n","    class_indict = json.load(json_file)\n","\n","    # create model\n","    model = resnet50(num_classes=2).to(device)\n","\n","    # load model weights\n","    weights_path = \"../input/resnetps/resnet.pth\"\n","    assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n","    model.load_state_dict(torch.load(weights_path))\n","\n","    model.eval()\n","    with torch.no_grad():\n","        # predict class\n","        output = torch.squeeze(model(img.to(device))[0]).cpu()\n","        predict = torch.softmax(output, dim=0)\n","        predict_cla = torch.argmax(predict).numpy()\n","\n","    print_res = \"class: {}   prob: {:.3f}\".format(class_indict[str(predict_cla)],\n","                                                  predict[predict_cla].numpy())\n","    plt.title(print_res)\n","    print(print_res)\n","    plt.show()\n","\n","\n","if __name__ == '__main__':\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-09-02T11:37:06.687467Z","iopub.status.busy":"2021-09-02T11:37:06.687048Z","iopub.status.idle":"2021-09-02T11:37:07.41214Z","shell.execute_reply":"2021-09-02T11:37:07.411095Z","shell.execute_reply.started":"2021-09-02T11:37:06.687381Z"},"trusted":true},"outputs":[],"source":["!/opt/bin/nvidia-smi"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
